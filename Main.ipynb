{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0         0       0       0       0       0       0       0       0       9   \n",
      "1         1       0       0       0       0       0       0       0       0   \n",
      "2         2       0       0       0       0       0       0      14      53   \n",
      "3         2       0       0       0       0       0       0       0       0   \n",
      "4         3       0       0       0       0       0       0       0       0   \n",
      "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "9995      0       0       0       0       0       0       0       0       0   \n",
      "9996      6       0       0       0       0       0       0       0       0   \n",
      "9997      8       0       0       0       0       0       0       0       0   \n",
      "9998      8       0       1       3       0       0       0       0       0   \n",
      "9999      1       0       0       0       0       0       0       0     140   \n",
      "\n",
      "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0          8  ...       103        87        56         0         0         0   \n",
      "1          0  ...        34         0         0         0         0         0   \n",
      "2         99  ...         0         0         0         0        63        53   \n",
      "3          0  ...       137       126       140         0       133       224   \n",
      "4          0  ...         0         0         0         0         0         0   \n",
      "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
      "9995       0  ...        32        23        14        20         0         0   \n",
      "9996       0  ...         0         0         0         2        52        23   \n",
      "9997       0  ...       175       172       172       182       199       222   \n",
      "9998       0  ...         0         0         0         0         0         1   \n",
      "9999     119  ...       111        95        75        44         1         0   \n",
      "\n",
      "      pixel781  pixel782  pixel783  pixel784  \n",
      "0            0         0         0         0  \n",
      "1            0         0         0         0  \n",
      "2           31         0         0         0  \n",
      "3          222        56         0         0  \n",
      "4            0         0         0         0  \n",
      "...        ...       ...       ...       ...  \n",
      "9995         1         0         0         0  \n",
      "9996        28         0         0         0  \n",
      "9997        42         0         1         0  \n",
      "9998         0         0         0         0  \n",
      "9999         0         0         0         0  \n",
      "\n",
      "[10000 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('datasets/fashion-mnist_test.csv')\n",
    "test_df = pd.read_csv('datasets/fashion-mnist_test.csv')\n",
    "\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "print (train_df)\n",
    "\n",
    "train_data = np.array(train_df.iloc[:, 1:])\n",
    "test_data = np.array(test_df.iloc[:, 1:])\n",
    "\n",
    "\n",
    "train_labels = to_categorical(train_df.iloc[:, 0])\n",
    "test_labels = to_categorical(test_df.iloc[:, 0])\n",
    "\n",
    "\n",
    "rows, cols = 28, 28\n",
    "\n",
    "train_data = train_data.reshape(train_data.shape[0], rows, cols, 1)\n",
    "test_data = test_data.reshape(test_data.shape[0], rows, cols, 1)\n",
    "\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "\n",
    "train_data /= 255.0\n",
    "test_data /= 255.0\n",
    "\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_data, train_labels, test_size=0.2)\n",
    "\n",
    "batch_size = 256\n",
    "epochs = 5\n",
    "input_shape = (rows, cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model ():\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = baseline_model()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-19-567fec920054>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-567fec920054>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    validation_data=(val_x, val_y)\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\devon\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\devon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\devon\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 8s 979us/step - loss: 2.2398 - acc: 0.2654 - val_loss: 1.3375 - val_acc: 0.6175\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 6s 783us/step - loss: 1.5182 - acc: 0.4459 - val_loss: 1.0394 - val_acc: 0.6535\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 6s 772us/step - loss: 1.2758 - acc: 0.5339 - val_loss: 0.8984 - val_acc: 0.7115\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 6s 781us/step - loss: 1.1255 - acc: 0.5924 - val_loss: 0.8140 - val_acc: 0.7280\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 6s 780us/step - loss: 1.0200 - acc: 0.6286 - val_loss: 0.7341 - val_acc: 0.7505\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= model.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.6882215e-01 4.0375958e-03 6.6435449e-02 ... 3.4245932e-03\n",
      "  7.2023617e-03 1.8345355e-03]\n",
      " [5.1638560e-04 9.5682544e-01 1.9004477e-04 ... 1.9051076e-04\n",
      "  1.3222573e-04 1.2735868e-04]\n",
      " [1.0700058e-01 6.0847313e-03 4.9692264e-01 ... 6.2475107e-03\n",
      "  1.1202348e-02 8.6065307e-03]\n",
      " ...\n",
      " [2.7297737e-04 2.2123286e-03 1.2585097e-02 ... 2.8518429e-03\n",
      "  9.5866597e-01 4.4414010e-03]\n",
      " [3.2549817e-02 7.6688449e-03 4.2704201e-01 ... 8.2605369e-03\n",
      "  2.1041031e-01 8.0297649e-02]\n",
      " [7.9905741e-02 1.5578002e-02 1.6504593e-01 ... 4.9777967e-03\n",
      "  1.4374114e-02 7.3093972e-03]]\n"
     ]
    }
   ],
   "source": [
    "print (predictions) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 28, 28, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 211,822\n",
      "Trainable params: 211,756\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
